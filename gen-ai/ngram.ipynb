{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnQpBUIXFeED3FcZW/YtqW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujithkumarmp/google-colab/blob/main/gen-ai/ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import Counter\n",
        "from itertools import islice\n",
        "\n",
        "# Sample text data\n",
        "text = \"We are learning PyTorch for building N-gram models. PyTorch is fun and powerful.\"\n",
        "\n",
        "# Preprocessing: Tokenize and create N-grams\n",
        "def generate_ngrams(tokens, n):\n",
        "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
        "\n",
        "tokens = text.lower().split()\n",
        "n = 3  # Trigram example\n",
        "ngrams = generate_ngrams(tokens, n)\n",
        "\n",
        "# Vocabulary and mapping\n",
        "vocab = set(tokens)\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "\n",
        "# Prepare data\n",
        "data = [(torch.tensor([word_to_idx[w] for w in ngram[:-1]], dtype=torch.long),\n",
        "         torch.tensor(word_to_idx[ngram[-1]], dtype=torch.long)) for ngram in ngrams]\n",
        "\n",
        "# Define the model\n",
        "class NGramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(NGramLanguageModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view(1, -1)\n",
        "        out = torch.relu(self.linear1(embeds))\n",
        "        out = self.linear2(out)\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "embedding_dim = 10\n",
        "context_size = n - 1\n",
        "model = NGramLanguageModel(len(vocab), embedding_dim, context_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    for context, target in data:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(context)\n",
        "        loss = loss_function(output, target.view(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Testing the model\n",
        "context = torch.tensor([word_to_idx[\"pytorch\"], word_to_idx[\"is\"]], dtype=torch.long)\n",
        "predicted = model(context).argmax(dim=1).item()\n",
        "print(f\"Prediction for context 'pytorch is': {idx_to_word[predicted]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ4Y6e7Sjrgk",
        "outputId": "64c49578-d59d-4b77-d882-c1bbf35ee90a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 26.7399\n",
            "Epoch 10, Loss: 11.6344\n",
            "Epoch 20, Loss: 4.7709\n",
            "Epoch 30, Loss: 2.3051\n",
            "Epoch 40, Loss: 1.3659\n",
            "Epoch 50, Loss: 0.9268\n",
            "Epoch 60, Loss: 0.6849\n",
            "Epoch 70, Loss: 0.5353\n",
            "Epoch 80, Loss: 0.4354\n",
            "Epoch 90, Loss: 0.3645\n",
            "Prediction for context 'pytorch is': fun\n"
          ]
        }
      ]
    }
  ]
}